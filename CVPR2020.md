# CVPR2020 创新点整理
在科研工作中，创新往往是在前人的积累之后的新思考，因此，我希望整理一些目前最新的研究工作，他们解决问题的思路，希望能够启发大家！



### 表情识别

https://github.com/EvelynFan/AWESOME-FER

**Label Distribution Learning on Auxiliary Label Space Graphs for Facial Expression Recognition**

> 作者 | Shikai Chen, Jianfeng Wang, Yuedong Chen, Zhongchao Shi, Xin Geng, Yong Rui
>
> 单位 | 东南大学；牛津大学；南洋理工大学；联想研究院
>
> 论文：https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Label_Distribution_Learning_on_Auxiliary_Label_Space_Graphs_for_Facial_CVPR_2020_paper.pdf

创新点：

摘要：

已有的许多研究表明，在多种面部表情识别(FER)数据集中，标注不一致现象普遍存在。其原因可能是人类注释者的主观性和表达标签的模糊性。解决这一问题的一个有前途的策略是最近提出的一种名为标签分布学习(LDL)的学习范式，它允许不同"强度"的多个标签连接到一个表达。然而，直接应用标签分布学习往往是不切实际的，因为许多现有数据集只包含 `one-hot` 标签，而不是标签分布。为了解决这一问题，我们提出了一种名为辅助标签空间图上标签分布学习**( Label Distribution Learning on Auxiliary Label Space Graphs(LDL-ALSG) )**的新方法，该方法利用了来自相关但更明显任务的标签的拓扑信息，如动作单元识别和人脸关键点检测。其基本假设是，在动作单元识别和人脸关键点检测的标签空间中，人脸图像与其相邻的图像应该具有相似的表情分布。我们提出的方法在各种数据集上进行了评估，并以以巨大的差距优于那些最先进的方法。





Suppressing Uncertainties for Large-Scale Facial Expression Recognition

作者 | Kai Wang, Xiaojiang Peng, Jianfei Yang, Shijian Lu, Yu Qiao

代码 | https://github.com/kaiwang960112/Self-Cure-Network

单位 | 商汤；南洋理工大学；中科院深圳先进技术研究院；国科大



### 人脸识别

Learning Meta Face Recognition in Unseen Domains

作者 | Jianzhu Guo, Xiangyu Zhu, Chenxu Zhao, Dong Cao, Zhen Lei, Stan Z. Li

代码 | https://github.com/cleardusk/MFR

单位 | 中科院；国科大；明略科技；西湖大学

论文：https://me.guojianzhu.com/assets/pdfs/05997.pdf

摘要：

人脸识别系统在实际应用中往往会遇到一些不可见的域，由于泛化程度较低，导致识别性能不理想。例如，一个在`webface` 数据上受过良好训练的模型不能在监视场景中处理 ID vs. Spott任务。在这篇文章中，我们的目标是学习一个广义的模型，可以直接处理新的看不见的领域，而不需要任何模型更新。为此，我们提出了一种新的基于元学习的人脸识别方法——元人脸识别(MFR)。MFR以元优化目标综合源/目标域的位移，这要求模型不仅要学习合成源域的有效表示，还要学习合成目标域的有效表示。具体来说，我们通过域级采样策略构建域转移批，并通过优化多域分布在合成的源/目标域上获得梯度/元辐射的反向传播。进一步结合梯度和元求导对模型进行更新，提高泛化能力。此外，我们提出了两个评价广义人脸识别的基准。在我们的基准测试上进行的实验验证了我们的泛化
方法比较了几个基线和其他技术的现状。

图1:用于广义人脸识别问题的MFR图。左列包含4个不同种族的源域，右列包括5个目标域:跨年龄(CACD-VS)、NIR-VIS人脸匹配(CASIA NIR-VIS 2.0)、大姿态(Multi-PIE)、眼镜遮挡(MeGlass)和ID - Spot (Public-IvS)，这些在训练中是看不到的。通过对源域中模拟的元数据/元测试转换的元学习，我们的模型可以学习跨域的可转移知识，从而在目标不可见的域上很好地泛化



---

### 人脸反欺骗

《Searching Central Difference Convolutional Networks for Face Anti-Spoofing》

作者 | Zitong Yu, Chenxu Zhao, Zezheng Wang, Yunxiao Qin, Zhuo Su, Xiaobai Li, Feng Zhou, Guoying Zhao

代码 | https://github.com/ZitongYu/CDCN

单位 | 奥卢大学，明略科技，Aibee，西工大

论文：https://arxiv.org/pdf/2003.04092v1.pdf

解读：https://cloud.tencent.com/developer/article/1628887

> 提出了一种基于中心差分卷积（CDC）的新型帧级FAS方法，它能够通过聚合强度和梯度信息来捕获内在的详细模式。用CDC构建的网络，称为中心差分卷积网络（CDCN），相较于用普通卷积构建的网络，能够提供更稳健的建模能力。

《Deep Spatial Gradient and Temporal Depth Learning for Face Anti-Spoofing》

作者 | Zezheng Wang, Zitong Yu, Chenxu Zhao, Xiangyu Zhu, Yunxiao Qin, Qiusheng Zhou, Feng Zhou, Zhen Lei

代码 | https://github.com/clks-wzz/FAS-SGTD

单位 | Aibee，奥卢大学，明略科技，中科院，西工大，京东

备注｜CVPR 2020 Oral

解读：https://cloud.tencent.com/developer/article/1628886

> 本文致力于从空间Spatial与时间Temporal层面来揭秘人脸防伪

《Cross-Domain Face Presentation Attack Detection via Multi-Domain Disentangled Representation Learning 》

作者 | Guoqing Wang, Hu Han, Shiguang Shan, Xilin Chen

单位 | 中科院；国科大；鹏城实验室

解读：https://zhuanlan.zhihu.com/p/111989834

> 目前，人脸呈现攻击检测(Presentation Attack Detection, 简称PAD)成为人脸识别系统中一个亟待解决的问题。传统的方法通常认为测试集和训练集来自于同一个域，结果表明这些方法并不能很好的推广到未知场景中，因为学到的特征表示可能会对训练集中的身份、光照等信息产生过拟合。
>
> 为此，本文针对跨域人脸呈现攻击检测提出一种高效的特征解耦方法。我们的方法包含特征解耦模块(DR-Net)和多域学习模块(MD-Net)。DR-Net通过生成模型学习了一对特征编码器，可以解耦得到PAD相关的特征和身份信息相关的特征。MD-Net利用来自于不同域中解耦得到的特征进一步学习和解耦，得到与域无关的解耦特征。在当前公开的几个数据集上的实验验证了所提方法的有效性。

《Single-Side Domain Generalization for Face Anti-Spoofing》

作者 | Yunpei Jia, Jie Zhang, Shiguang Shan, Xilin Chen

代码 | https://github.com/taylover-pei/SSDG-CVPR2020

单位 | 中科院；国科大

> 由于不同数据集之间存在差异，很多活体检测方法进行跨数据集测试时性能下降明显。现有的一些方法借用领域泛化的思想，利用多个已有的源域数据去训练模型，以得到一个领域不变的特征空间，从而在未知的目标域中进行测试时能利用学习到的通用判别特征，去提升模型的泛化性能。但是，由于不同数据集之间，攻击样本相对于正常样本存在更大的差异（比如说攻击方式的不同，攻击样本之间采集的环境差异），努力让这些攻击样本去学习一个领域不变的特征空间是比较困难的，通常会得到一个次优解，如下图左边所示。因此，针对这一个问题，我们提出来一个端到端的单边领域泛化框架，以进一步提升模型的性能。
>
> 其中主要思想在于，对于不同数据集中的正常样本，我们去学习一个领域不变的特征空间；但是对于不同数据集中的攻击样本，我们去学习一个具有分辨性的特征空间，使相同数据集中的攻击样本尽可能接近，而不同数据集中的攻击样本尽可能远离。最终效果会使攻击样本在特征空间中张成更大的区域，而正常样本仅仅处在一个紧凑的区域中，从而能够学习到一个对于正常样本包围更紧致的分类器，以达到在未知的目标域上更好的性能，如下图右边所示。
>
> 具体来说，我们引用一个域判别器，利用一种单边的对抗学习，让特征提取器仅仅对于正常样本提取更具有泛化性能的特征。并且，我们提出一个不均衡的三元组损失函数，让不同数据集之间的正常样本尽可能接近而攻击样本尽可能远离，以使得攻击样本在特征空间中张成一个更大的范围。同时，我们还引入了特征和参数归一化的思想，进一步地提升模型的性能。大量实验表明，我们提出的方法是有效的，并且在四个公开数据库上均达到了最优的性能。

 **人脸伪造检测、**假脸检测****

《 Face X-Ray for More General Face Forgery Detection 》

作者 | Lingzhi Li, Jianmin Bao, Ting Zhang, Hao Yang, Dong Chen, Fang Wen, Baining Guo

代码 | https://github.com/neverUseThisName/Face-X-Ray（非官方）

单位 | 北大；微软亚洲研究院

备注｜CVPR 2020 Oral

解读：https://www.linkresearcher.com/theses/8b4ff565-af5f-4a45-84f7-eb3e4c28a524

> 本文介绍了微软亚洲研究院的研究者被 CVPR 2020 接收的一篇论文，其提出给换脸图像做「X-Ray」，检测图像是否是合成图片，并指出合成的边界，兼备了识别和解释两种特性。

《DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery Detection》

作者 | Liming Jiang, Ren Li, Wayne Wu, Chen Qian, Chen Change Loy

代码 | https://github.com/EndlessSora/DeeperForensics-1.0

网站 | https://liming-jiang.com/projects/DrF1/DrF1.html

单位 | 南洋理工大学，商汤科技

解读：https://www.cnblogs.com/panicwq/p/12382651.html

> 该文章由新加坡南洋理工大学和商汤科技合作研究发布，该文主要根据现有的相关的数据集的缺点和主要面临的挑战，提出了Deeperforensics-1.0数据集，并提出了新的测试基准。

《 On the Detection of Digital Face Manipulation》

作者 | Hao Dang, Feng Liu, Joel Stehouwer, Xiaoming Liu, Anil K. Jain

代码 | http://cvlab.cse.msu.edu/project-ffd.html

单位 | 密歇根州立大学

> 【31】文[31]提出了一种基于隐写分析和自然图像统计的检测系统。特别是，他们的方法是基于像素共生矩阵和CNNs的组合，还提出了一种鲁棒性分析的方法分析不同gan的鲁棒性
> *Detecting GAN Generated Fake Images Using Co-Occurrence Matrices,arXiv preprint arXiv*
> 【11】他们提出的基于XceptionNet模型的检测方法，能够正确地检测出新的GANs生成的网络图像。简单看了一下，本文主要提出一种可以将fingerprint去除的基于autoencoder的方法，以欺骗检测系统。

《Global Texture Enhancement for Fake Face Detection in the Wild》

作者 | Zhengzhe Liu, Xiaojuan Qi, Philip H.S. Torr

单位 | 牛津大学；香港大学





假脸相关的博客：

https://zhuanlan.zhihu.com/p/92474937

https://zhuanlan.zhihu.com/p/115070797